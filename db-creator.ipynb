{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import bs4\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\billy\\Desktop\\py\\ffnorma\\data_src\"\n",
    "\n",
    "# bazy a(aktywne), w(wycofane)\n",
    "db_a = []\n",
    "db_w = []\n",
    "\n",
    "# baza A\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith(\"A.html\"): \n",
    "\n",
    "        with open(f\"{data_path}\\\\{filename}\", encoding=\"utf-8\") as website:\n",
    "            soup = bs4.BeautifulSoup(website, \"html.parser\")\n",
    "\n",
    "        blocks = soup.find_all(\"div\", class_=\"p4s-search-results-values\")    \n",
    "\n",
    "        for b in blocks:\n",
    "            tytul = None\n",
    "            numer = None\n",
    "            zastepuje = []\n",
    "\n",
    "            if len(b.find_all(\"span\", string=re.compile(\"Tytuł normy\"))) == 0:\n",
    "                tytul = \"\"\n",
    "            else:\n",
    "                tytul = str(\n",
    "                            b.find_all(\n",
    "                                \"span\", string=re.compile(\"Tytuł normy\")\n",
    "                            )[0].find_next(\"a\").string\n",
    "                        ).replace('\\t', '').replace('\\n', '')\n",
    "                \n",
    "                numer = \"PN\"+ str(\n",
    "                                b.find_all(\n",
    "                                    \"span\", class_=\"highlighted-search-term\"\n",
    "                                )[0].next_sibling\n",
    "                            ).replace('\\t', '').replace('\\n', '')\n",
    "\n",
    "                if len(b.find_all(string=re.compile(\"Zastępuje\"))) != 0:\n",
    "                    zastapione_normy = b.find_all(\n",
    "                                            string=re.compile(\"Zastępuje\")\n",
    "                                        )[0].parent.parent.next_sibling.find_next(\"ul\").find_all(\"a\")\n",
    "                    for z in zastapione_normy:\n",
    "                        try:\n",
    "                            z = z.contents[0].replace('\\t', '').replace('\\n', '')\n",
    "                        except IndexError:\n",
    "                            z = ''\n",
    "                        zastepuje.append(z)\n",
    "\n",
    "            db_a.append((tytul, numer, zastepuje))\n",
    "\n",
    "db_filtered = list(filter(lambda x: x[0] is not '', db_a))\n",
    "\n",
    "\n",
    "# baza W\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith(\"W.html\"):\n",
    "        with open(f\"{data_path}\\\\{filename}\", encoding=\"utf-8\") as website:\n",
    "            soup_w = bs4.BeautifulSoup(website, \"html.parser\")\n",
    "\n",
    "        blocks_w = soup_w.find_all(\"div\", class_=\"p4s-search-results-values\")    \n",
    "\n",
    "        for b in blocks_w:\n",
    "            numer = \"\"\n",
    "            zastepuje = []\n",
    "\n",
    "            if len(b.find_all(\"span\", string=re.compile(\"Tytuł normy\"))) == 0:\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                numer = \"PN\"+ str(b.find_all(\"span\", class_=\"highlighted-search-term\")[0].next_sibling).replace('\\t', '').replace('\\n', '')\n",
    "\n",
    "                if len(b.find_all(string=re.compile(\"Zastępuje\"))) != 0:\n",
    "                            zastapione_normy = b.find_all(string=re.compile(\"Zastępuje\"))[0].parent.parent.next_sibling.find_next(\"ul\").find_all(\"a\")\n",
    "                            for z in zastapione_normy:\n",
    "                                try:\n",
    "                                    z = z.contents[0].replace('\\t', '').replace('\\n', '')\n",
    "                                except IndexError:\n",
    "                                    z = ''\n",
    "                                zastepuje.append(z)\n",
    "\n",
    "            db_w.append((numer, zastepuje))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_w_tab = []\n",
    "\n",
    "for i in range(len(db_w)):\n",
    "    temp = [db_w[i][0]]\n",
    "    temp.extend(db_w[i][1])\n",
    "    db_w_tab.append(set(temp))\n",
    "    \n",
    "for s in range(len(db_w_tab)):\n",
    "    for i in range(s+1, len(db_w_tab)):\n",
    "        if len(db_w_tab[s].intersection(db_w_tab[i])) > 0:\n",
    "            db_w_tab[s].union(db_w_tab[i])\n",
    "            db_w_tab[i] = set()\n",
    "            \n",
    "w_reduced = []\n",
    "for e in db_w_tab:\n",
    "    if e != set():\n",
    "        w_reduced.append(e)\n",
    "\n",
    "# Dana jest lista tupli aktualnych norm z normami zastępującymi ('Tytul', 'Numer aktualnej', [lista numerów nieaktualnych])\n",
    "# oraz lista zbiorów {'nieaktualnych, powiązanych ze sobą numerów norm', ... }\n",
    "merge_db = []\n",
    "\n",
    "for element in db_filtered:\n",
    "    merged_olds = set(element[2])\n",
    "    \n",
    "    for old_norm in w_reduced:\n",
    "        if len(merged_olds.intersection(old_norm)) > 0:\n",
    "            merged_olds.union(old_norm)\n",
    "                \n",
    "    merge_db.append((element[0], element[1], merged_olds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisywanie do CSV\n",
    "\n",
    "with open(\"db.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as dbfile:\n",
    "    writer = csv.writer(dbfile, delimiter=',')\n",
    "    writer.writerows(merge_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie CSV do listy\n",
    "# csv_read = []\n",
    "\n",
    "# with open(\"db.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as readdb:\n",
    "#     reader = csv.reader(readdb, delimiter=',')\n",
    "#     for row in reader:\n",
    "#         csv_read.append((row[0], row[1], eval(row[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
